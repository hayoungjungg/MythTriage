{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b6ae643-3df0-4708-874a-33accf973244",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import random\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "import math\n",
    "import argparse\n",
    "from collections import defaultdict, Counter\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from torch.utils.data.dataset import Subset\n",
    "import torch.nn.functional as F\n",
    "from torcheval.metrics.functional import multiclass_f1_score\n",
    "import logging\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "import wandb\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "random.seed(420)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f161695a-9b82-4660-8763-3aef5f59378e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad3fb0a9-961e-43cc-8d12-a91a305e650e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Free:47.445GB\tAvailable:47.726GB\n"
     ]
    }
   ],
   "source": [
    "def get_memory_usage(idx=\"\"):\n",
    "    free, available = torch.cuda.mem_get_info()\n",
    "    print(f\"{idx} Free:{free/1000000000:.3f}GB\\tAvailable:{available/1000000000:.3f}GB\")\n",
    "get_memory_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f89428-75f1-46ff-a9af-00c0b23aad25",
   "metadata": {},
   "source": [
    "## Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995f7a17-e026-44ea-9c74-a529e90523d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_trained_model(modelname, bool_tokenizer=True, bool_model=True):\n",
    "    if bool_tokenizer:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(modelname, use_fast=False, truncation=True, max_len=MAX_LEN, padding='max_length', cache_dir=\"/gscratch/argon/hjung10/transformers\")\n",
    "    else:\n",
    "        tokenizer = None\n",
    "        \n",
    "    if bool_model:\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(PATH_MODEL_SAVE, num_labels=3, cache_dir=\"/gscratch/argon/hjung10/transformers\").to(device)\n",
    "    else:\n",
    "        model = None\n",
    "    if tokenizer and tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b455cb9f-d687-44a8-b860-67fddf4b8ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "MYTH = 'M3'\n",
    "PATH_MODEL_SAVE = '/mmfs1/home/hjung10/models/deberta-v3-base-oud-' + MYTH\n",
    "\n",
    "MAX_LEN = 1024\n",
    "MODEL_NAME = \"microsoft/deberta-v3-base\"\n",
    "model, tokenizer = initialize_trained_model(MODEL_NAME, bool_tokenizer=True, bool_model=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ced9cae-e2f8-4f2f-9497-e83e5feae18a",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e75dc5f-2f5a-43f7-9e5c-97354bc67077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_training_data(TRAINING_DIR, drop_columns):\n",
    "    df_data = pd.read_csv(TRAINING_DIR)\n",
    "    df_data = df_data.drop_duplicates(subset='video_id')\n",
    "\n",
    "    df_data = df_data.drop(axis=1, columns=drop_columns).reset_index()\n",
    "    print(\"Shape of dataframe: \" + str(df_data.shape))\n",
    "    return df_data\n",
    "\n",
    "def load_data_for_labeling(TRAINING_DIR, drop_columns, exclude_video_id):\n",
    "    df_data = pd.read_csv(TRAINING_DIR)\n",
    "    df_data = df_data.drop_duplicates(subset='video_id')\n",
    "\n",
    "    df_data = df_data.drop(axis=1, columns=drop_columns).reset_index()\n",
    "\n",
    "    print(\"Shape of dataframe before excluding: \" + str(df_data.shape))\n",
    "    df_data = df_data[~df_data['video_id'].isin(exclude_video_id)]\n",
    "    print(\"Shape of dataframe after excluding: \" + str(df_data.shape))\n",
    "    return df_data\n",
    "\n",
    "def process_input_text(row):\n",
    "    title = row['video_title'] if row['video_title'] == row['video_title'] else \"\"\n",
    "    if title == \"\":\n",
    "        return None\n",
    "    description = row['video_description'] if row['video_description'] == row['video_description'] else \"\"\n",
    "\n",
    "    transcript = \"\"\n",
    "    if row['transcript'] == row['transcript'] and \"Could not retrieve a transcript for\" not in row['transcript']:\n",
    "        transcript = row['transcript']\n",
    "\n",
    "    tags = row['tags'] if row['tags'] == row['tags'] else \"\"\n",
    "    input = 'VIDEO TITLE: ' + title + '\\nVIDEO DESCRIPTION: ' + description + '\\nVIDEO TRANSCRIPT: ' + transcript + '\\nVIDEO TAGS: ' + tags\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d86657a3-391f-49cc-af71-022e3207d9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "### incrementing labels by 1 since prediction index starts from 0\n",
    "## 0 -> opposing\n",
    "### 1 -> neutral\n",
    "### 2 -> supporting\n",
    "def process_data_for_prediction(data):\n",
    "    processed = []\n",
    "    url_not_accessible = []\n",
    "    for i, row  in data.iterrows():\n",
    "        if i % 200 == 1:\n",
    "            #print(original_)\n",
    "            print(i)\n",
    "\n",
    "        # processing inputs and labels\n",
    "        original_ = process_input_text(row)\n",
    "        if original_ is None:   # deleted video\n",
    "            url_not_accessible.append(row['video_id'])\n",
    "            continue\n",
    "        instance = [original_, row['video_id']]\n",
    "        \n",
    "        tokenized = tokenizer(instance[0], max_length=MAX_LEN, padding = 'max_length', truncation=True, return_tensors='pt') #.to(device)\n",
    "        if 'token_type_ids' in tokenized:\n",
    "            tokenized = {'input_ids':tokenized['input_ids'][0], 'token_type_ids':tokenized['token_type_ids'][0], 'attention_mask':tokenized['attention_mask'][0]}\n",
    "        else:\n",
    "            tokenized = {'input_ids':tokenized['input_ids'][0], 'attention_mask':tokenized['attention_mask'][0]}\n",
    "    \n",
    "        instance[0]=tokenized\n",
    "        processed.append(instance)\n",
    "    return processed, url_not_accessible\n",
    "\n",
    "def save_list_to_json(data, filename):\n",
    "    list_example = []\n",
    "    for example in data_dev:\n",
    "        list_example.append(example[2])\n",
    "    \n",
    "    \"\"\"Saves a list into a JSON file.\"\"\"\n",
    "    with open(filename, 'w') as file:\n",
    "        json.dump(list_example, file, indent=4)\n",
    "\n",
    "def read_list_from_json(filename):\n",
    "    \"\"\"Reads a list from a JSON file.\"\"\"\n",
    "    with open(filename, 'r') as file:\n",
    "        return json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5a9b3d-d2c8-4edd-80e3-1a2f5df48b34",
   "metadata": {},
   "source": [
    "## Reading, processing, and creating dataloader\n",
    "- Note: 274/164,085 unique videos were URL not accessible; assigned 0 (neutral) automatically following past works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3698602a-eca9-4b6f-be30-99f82a143b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomData(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84b2b11d-8d69-44b9-9702-19e778ddd02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch size\n",
    "VALID_BATCH_SIZE = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8d66c38-3e8e-4b33-9dd2-d8dc97c07d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataframe: (1776, 27)\n"
     ]
    }
   ],
   "source": [
    "# Already annotated search results; exclude\n",
    "SEARCH_DATA_DIR = os.getcwd() + os.sep + 'training_data' + os.sep + 'final-search-results-annotations.csv'\n",
    "columns_to_drop = ['Unnamed: 0.1', 'Unnamed: 0']\n",
    "df_data = load_training_data(SEARCH_DATA_DIR, columns_to_drop)\n",
    "video_id_exclude = set(df_data['video_id'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4496dbda-06b3-41d2-ba5c-61e91877e325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataframe before excluding: (164085, 16)\n",
      "Shape of dataframe after excluding: (163744, 16)\n",
      "(163744, 16)\n"
     ]
    }
   ],
   "source": [
    "# reading in the recommendation data, excluding any of the search results that we already labeled\n",
    "TRAINING_DATA_DIR = os.getcwd() + os.sep + 'recommendation-data' + os.sep + 'recommendation-video-metadata.csv'\n",
    "columns_to_drop = ['Unnamed: 0.1', 'Unnamed: 0']\n",
    "df_data = load_data_for_labeling(TRAINING_DATA_DIR, columns_to_drop, video_id_exclude)\n",
    "print(df_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b591a0ae-653d-4083-9e76-51299259d52c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "201\n",
      "401\n",
      "601\n",
      "801\n",
      "1001\n",
      "1201\n",
      "1401\n",
      "1601\n",
      "1801\n",
      "2001\n",
      "2201\n",
      "2401\n",
      "2601\n",
      "2801\n",
      "3001\n",
      "3201\n",
      "3401\n",
      "3601\n",
      "3801\n",
      "4001\n",
      "4201\n",
      "4401\n",
      "4601\n",
      "4801\n",
      "5001\n",
      "5201\n",
      "5401\n",
      "5601\n",
      "5801\n",
      "6001\n",
      "6201\n",
      "6401\n",
      "6601\n",
      "6801\n",
      "7001\n",
      "7201\n",
      "7401\n",
      "7601\n",
      "7801\n",
      "8001\n",
      "8201\n",
      "8401\n",
      "8601\n",
      "8801\n",
      "9001\n",
      "9201\n",
      "9401\n",
      "9601\n",
      "9801\n",
      "10001\n",
      "10201\n",
      "10401\n",
      "10601\n",
      "10801\n",
      "11001\n",
      "11201\n",
      "11401\n",
      "11601\n",
      "11801\n",
      "12001\n",
      "12201\n",
      "12401\n",
      "12601\n",
      "12801\n",
      "13001\n",
      "13201\n",
      "13401\n",
      "13601\n",
      "13801\n",
      "14001\n",
      "14201\n",
      "14401\n",
      "14601\n",
      "14801\n",
      "15001\n",
      "15201\n",
      "15401\n",
      "15601\n",
      "15801\n",
      "16001\n",
      "16201\n",
      "16401\n",
      "16601\n",
      "16801\n",
      "17001\n",
      "17201\n",
      "17401\n",
      "17601\n",
      "17801\n",
      "18001\n",
      "18201\n",
      "18401\n",
      "18601\n",
      "18801\n",
      "19001\n",
      "19201\n",
      "19401\n",
      "19601\n",
      "19801\n",
      "20001\n",
      "20201\n",
      "20401\n",
      "20601\n",
      "20801\n",
      "21001\n",
      "21201\n",
      "21401\n",
      "21601\n",
      "21801\n",
      "22001\n",
      "22201\n",
      "22401\n",
      "22601\n",
      "22801\n",
      "23001\n",
      "23201\n",
      "23401\n",
      "23601\n",
      "23801\n",
      "24001\n",
      "24201\n",
      "24401\n",
      "24601\n",
      "24801\n",
      "25001\n",
      "25201\n",
      "25401\n",
      "25601\n",
      "25801\n",
      "26001\n",
      "26201\n",
      "26401\n",
      "26601\n",
      "26801\n",
      "27001\n",
      "27201\n",
      "27401\n",
      "27601\n",
      "27801\n",
      "28001\n",
      "28201\n",
      "28401\n",
      "28601\n",
      "28801\n",
      "29001\n",
      "29201\n",
      "29401\n",
      "29601\n",
      "29801\n",
      "30001\n",
      "30201\n",
      "30601\n",
      "30801\n",
      "31001\n",
      "31201\n",
      "31401\n",
      "31601\n",
      "31801\n",
      "32001\n",
      "32201\n",
      "32401\n",
      "32601\n",
      "32801\n",
      "33001\n",
      "33201\n",
      "33401\n",
      "33601\n",
      "33801\n",
      "34001\n",
      "34201\n",
      "34401\n",
      "34601\n",
      "34801\n",
      "35001\n",
      "35201\n",
      "35401\n",
      "35601\n",
      "35801\n",
      "36001\n",
      "36201\n",
      "36401\n",
      "36601\n",
      "36801\n",
      "37001\n",
      "37201\n",
      "37401\n",
      "37601\n",
      "37801\n",
      "38001\n",
      "38201\n",
      "38401\n",
      "38601\n",
      "38801\n",
      "39001\n",
      "39201\n",
      "39401\n",
      "39601\n",
      "39801\n",
      "40001\n",
      "40201\n",
      "40401\n",
      "40601\n",
      "40801\n",
      "41001\n",
      "41201\n",
      "41401\n",
      "41601\n",
      "41801\n",
      "42001\n",
      "42201\n",
      "42401\n",
      "42601\n",
      "42801\n",
      "43001\n",
      "43201\n",
      "43401\n",
      "43601\n",
      "43801\n",
      "44001\n",
      "44201\n",
      "44401\n",
      "44601\n",
      "44801\n",
      "45001\n",
      "45201\n",
      "45401\n",
      "45601\n",
      "45801\n",
      "46001\n",
      "46201\n",
      "46401\n",
      "46601\n",
      "46801\n",
      "47001\n",
      "47201\n",
      "47401\n",
      "47601\n",
      "47801\n",
      "48001\n",
      "48201\n",
      "48401\n",
      "48601\n",
      "48801\n",
      "49001\n",
      "49201\n",
      "49401\n",
      "49601\n",
      "49801\n",
      "50001\n",
      "50201\n",
      "50401\n",
      "50601\n",
      "50801\n",
      "51001\n",
      "51201\n",
      "51401\n",
      "51601\n",
      "51801\n",
      "52001\n",
      "52201\n",
      "52401\n",
      "52601\n",
      "52801\n",
      "53001\n",
      "53201\n",
      "53401\n",
      "53601\n",
      "53801\n",
      "54001\n",
      "54201\n",
      "54401\n",
      "54601\n",
      "54801\n",
      "55001\n",
      "55201\n",
      "55401\n",
      "55601\n",
      "55801\n",
      "56001\n",
      "56201\n",
      "56401\n",
      "56601\n",
      "56801\n",
      "57001\n",
      "57201\n",
      "57401\n",
      "57601\n",
      "57801\n",
      "58001\n",
      "58201\n",
      "58401\n",
      "58601\n",
      "58801\n",
      "59001\n",
      "59201\n",
      "59401\n",
      "59601\n",
      "59801\n",
      "60001\n",
      "60201\n",
      "60401\n",
      "60601\n",
      "60801\n",
      "61001\n",
      "61201\n",
      "61401\n",
      "61601\n",
      "61801\n",
      "62001\n",
      "62201\n",
      "62401\n",
      "62601\n",
      "62801\n",
      "63001\n",
      "63201\n",
      "63401\n",
      "63601\n",
      "63801\n",
      "64001\n",
      "64201\n",
      "64401\n",
      "64601\n",
      "64801\n",
      "65001\n",
      "65201\n",
      "65401\n",
      "65601\n",
      "65801\n",
      "66001\n",
      "66201\n",
      "66401\n",
      "66601\n",
      "66801\n",
      "67001\n",
      "67201\n",
      "67401\n",
      "67601\n",
      "67801\n",
      "68001\n",
      "68201\n",
      "68401\n",
      "68601\n",
      "68801\n",
      "69001\n",
      "69201\n",
      "69401\n",
      "69601\n",
      "69801\n",
      "70001\n",
      "70201\n",
      "70401\n",
      "70601\n",
      "70801\n",
      "71001\n",
      "71201\n",
      "71401\n",
      "71601\n",
      "71801\n",
      "72001\n",
      "72201\n",
      "72401\n",
      "72601\n",
      "72801\n",
      "73001\n",
      "73201\n",
      "73401\n",
      "73601\n",
      "73801\n",
      "74001\n",
      "74201\n",
      "74401\n",
      "74601\n",
      "74801\n",
      "75001\n",
      "75201\n",
      "75401\n",
      "75601\n",
      "75801\n",
      "76001\n",
      "76201\n",
      "76401\n",
      "76601\n",
      "76801\n",
      "77001\n",
      "77201\n",
      "77401\n",
      "77601\n",
      "77801\n",
      "78001\n",
      "78201\n",
      "78401\n",
      "78601\n",
      "78801\n",
      "79001\n",
      "79201\n",
      "79401\n",
      "79601\n",
      "79801\n",
      "80001\n",
      "80201\n",
      "80401\n",
      "80601\n",
      "80801\n",
      "81001\n",
      "81201\n",
      "81401\n",
      "81601\n",
      "81801\n",
      "82001\n",
      "82201\n",
      "82401\n",
      "82601\n",
      "82801\n",
      "83001\n",
      "83201\n",
      "83401\n",
      "83601\n",
      "83801\n",
      "84001\n",
      "84201\n",
      "84401\n",
      "84601\n",
      "84801\n",
      "85001\n",
      "85201\n",
      "85401\n",
      "85601\n",
      "85801\n",
      "86001\n",
      "86201\n",
      "86401\n",
      "86601\n",
      "86801\n",
      "87001\n",
      "87201\n",
      "87401\n",
      "87601\n",
      "87801\n",
      "88001\n",
      "88201\n",
      "88401\n",
      "88601\n",
      "88801\n",
      "89001\n",
      "89201\n",
      "89401\n",
      "89601\n",
      "89801\n",
      "90001\n",
      "90201\n",
      "90401\n",
      "90601\n",
      "90801\n",
      "91001\n",
      "91201\n",
      "91401\n",
      "91601\n",
      "91801\n",
      "92001\n",
      "92201\n",
      "92401\n",
      "92601\n",
      "92801\n",
      "93001\n",
      "93201\n",
      "93401\n",
      "93601\n",
      "93801\n",
      "94001\n",
      "94201\n",
      "94401\n",
      "94601\n",
      "94801\n",
      "95001\n",
      "95201\n",
      "95401\n",
      "95601\n",
      "95801\n",
      "96001\n",
      "96201\n",
      "96401\n",
      "96601\n",
      "96801\n",
      "97001\n",
      "97201\n",
      "97401\n",
      "97601\n",
      "97801\n",
      "98001\n",
      "98201\n",
      "98401\n",
      "98601\n",
      "98801\n",
      "99001\n",
      "99201\n",
      "99401\n",
      "99601\n",
      "99801\n",
      "100001\n",
      "100201\n",
      "100401\n",
      "100601\n",
      "100801\n",
      "101001\n",
      "101201\n",
      "101401\n",
      "101601\n",
      "101801\n",
      "102001\n",
      "102201\n",
      "102401\n",
      "102601\n",
      "102801\n",
      "103001\n",
      "103201\n",
      "103401\n",
      "103601\n",
      "103801\n",
      "104001\n",
      "104201\n",
      "104401\n",
      "104601\n",
      "104801\n",
      "105001\n",
      "105201\n",
      "105401\n",
      "105601\n",
      "105801\n",
      "106001\n",
      "106201\n",
      "106401\n",
      "106601\n",
      "106801\n",
      "107001\n",
      "107201\n",
      "107401\n",
      "107601\n",
      "107801\n",
      "108001\n",
      "108201\n",
      "108401\n",
      "108601\n",
      "108801\n",
      "109001\n",
      "109201\n",
      "109401\n",
      "109601\n",
      "109801\n",
      "110001\n",
      "110201\n",
      "110401\n",
      "110601\n",
      "110801\n",
      "111001\n",
      "111201\n",
      "111401\n",
      "111601\n",
      "111801\n",
      "112001\n",
      "112201\n",
      "112401\n",
      "112601\n",
      "112801\n",
      "113001\n",
      "113201\n",
      "113401\n",
      "113601\n",
      "113801\n",
      "114001\n",
      "114201\n",
      "114401\n",
      "114601\n",
      "114801\n",
      "115001\n",
      "115201\n",
      "115401\n",
      "115601\n",
      "115801\n",
      "116001\n",
      "116201\n",
      "116401\n",
      "116601\n",
      "116801\n",
      "117001\n",
      "117201\n",
      "117401\n",
      "117601\n",
      "117801\n",
      "118001\n",
      "118201\n",
      "118401\n",
      "118601\n",
      "118801\n",
      "119001\n",
      "119201\n",
      "119401\n",
      "119601\n",
      "119801\n",
      "120001\n",
      "120201\n",
      "120401\n",
      "120601\n",
      "120801\n",
      "121001\n",
      "121201\n",
      "121401\n",
      "121601\n",
      "121801\n",
      "122001\n",
      "122201\n",
      "122401\n",
      "122601\n",
      "122801\n",
      "123001\n",
      "123201\n",
      "123401\n",
      "123601\n",
      "123801\n",
      "124001\n",
      "124201\n",
      "124401\n",
      "124601\n",
      "124801\n",
      "125001\n",
      "125201\n",
      "125401\n",
      "125601\n",
      "125801\n",
      "126001\n",
      "126201\n",
      "126401\n",
      "126601\n",
      "126801\n",
      "127001\n",
      "127201\n",
      "127401\n",
      "127601\n",
      "127801\n",
      "128001\n",
      "128201\n",
      "128401\n",
      "128601\n",
      "128801\n",
      "129001\n",
      "129201\n",
      "129401\n",
      "129601\n",
      "129801\n",
      "130001\n",
      "130201\n",
      "130401\n",
      "130601\n",
      "130801\n",
      "131001\n",
      "131201\n",
      "131401\n",
      "131601\n",
      "131801\n",
      "132001\n",
      "132401\n",
      "132601\n",
      "132801\n",
      "133001\n",
      "133201\n",
      "133401\n",
      "133601\n",
      "133801\n",
      "134001\n",
      "134201\n",
      "134401\n",
      "134601\n",
      "134801\n",
      "135001\n",
      "135201\n",
      "135401\n",
      "135601\n",
      "135801\n",
      "136001\n",
      "136201\n",
      "136401\n",
      "136601\n",
      "136801\n",
      "137001\n",
      "137201\n",
      "137401\n",
      "137601\n",
      "137801\n",
      "138001\n",
      "138201\n",
      "138401\n",
      "138601\n",
      "138801\n",
      "139001\n",
      "139201\n",
      "139401\n",
      "139601\n",
      "139801\n",
      "140001\n",
      "140201\n",
      "140401\n",
      "140601\n",
      "140801\n",
      "141001\n",
      "141401\n",
      "141601\n",
      "141801\n",
      "142001\n",
      "142201\n",
      "142401\n",
      "142601\n",
      "142801\n",
      "143001\n",
      "143201\n",
      "143401\n",
      "143601\n",
      "143801\n",
      "144001\n",
      "144201\n",
      "144401\n",
      "144601\n",
      "144801\n",
      "145001\n",
      "145201\n",
      "145401\n",
      "145601\n",
      "145801\n",
      "146001\n",
      "146201\n",
      "146401\n",
      "146601\n",
      "146801\n",
      "147001\n",
      "147201\n",
      "147401\n",
      "147601\n",
      "147801\n",
      "148001\n",
      "148201\n",
      "148401\n",
      "148601\n",
      "148801\n",
      "149001\n",
      "149201\n",
      "149401\n",
      "149601\n",
      "149801\n",
      "150001\n",
      "150201\n",
      "150401\n",
      "150601\n",
      "150801\n",
      "151001\n",
      "151201\n",
      "151401\n",
      "151601\n",
      "151801\n",
      "152001\n",
      "152201\n",
      "152401\n",
      "152601\n",
      "152801\n",
      "153001\n",
      "153201\n",
      "153401\n",
      "153601\n",
      "153801\n",
      "154001\n",
      "154201\n",
      "154401\n",
      "154601\n",
      "154801\n",
      "155001\n",
      "155201\n",
      "155401\n",
      "155601\n",
      "155801\n",
      "156001\n",
      "156201\n",
      "156401\n",
      "156601\n",
      "156801\n",
      "157001\n",
      "157201\n",
      "157401\n",
      "157601\n",
      "157801\n",
      "158001\n",
      "158201\n",
      "158401\n",
      "158601\n",
      "158801\n",
      "159001\n",
      "159201\n",
      "159401\n",
      "159601\n",
      "159801\n",
      "160001\n",
      "160201\n",
      "160401\n",
      "160601\n",
      "160801\n",
      "161001\n",
      "161201\n",
      "161401\n",
      "161601\n",
      "161801\n",
      "162001\n",
      "162201\n",
      "162401\n",
      "162601\n",
      "162801\n",
      "163001\n",
      "163201\n",
      "163401\n",
      "163601\n",
      "163801\n",
      "164001\n",
      "Number of url not accessible: 274\n"
     ]
    }
   ],
   "source": [
    "# processing data & placing into data loader\n",
    "data_for_prediction, url_not_accessible = process_data_for_prediction(df_data)\n",
    "print(\"Number of url not accessible: \" + str(len(url_not_accessible)))\n",
    "dataloader_pred = DataLoader(CustomData(data_for_prediction), batch_size=VALID_BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be69e7da-b5a3-4fa0-b2f8-a6e87a646526",
   "metadata": {},
   "source": [
    "## Labeling Recommendation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1993b0e8-a951-4af3-8ef2-c01f9ed85610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation against the provided validation/test dataloader\n",
    "def predict(dataloder):\n",
    "    model.eval()\n",
    "    model_prediction = []\n",
    "\n",
    "    raw_predictions = []\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(dataloder):\n",
    "            if i % 100 == 1:\n",
    "                print(i)\n",
    "                print(model_prediction[i-1])\n",
    "                print(Counter(raw_predictions))\n",
    "            input, video_id = batch\n",
    "            input = {k:v.to(device) for k,v in input.items()}\n",
    "            outputs = model(**input)\n",
    "            logits = outputs.logits\n",
    "            probs = F.softmax(logits, dim=1)            \n",
    "            max_probs, pred_idx = probs.max(dim=1)\n",
    "\n",
    "            pred_idx_cpu = pred_idx.cpu()\n",
    "            for i in range(len(pred_idx_cpu)):\n",
    "                prediction_idx = pred_idx_cpu[i].item()\n",
    "                confidence = max_probs[i].item()\n",
    "                raw_predictions.append(prediction_idx)\n",
    "                model_prediction.append((video_id[i], prediction_idx, confidence))\n",
    "    return model_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "04275ca8-b0a9-4f7a-917f-d4e572536f92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mmfs1/home/hjung10/models/deberta-v3-base-oud-M3'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH_MODEL_SAVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e5c47e-009b-434c-b838-dec12e043228",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = time.perf_counter()\n",
    "model_prediction = predict(dataloader_pred)\n",
    "end = time.perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bbc92a-0335-4ac0-ae7a-71afc7ca80ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store model predictions; figure out which videos to propagate up to GPT-4o\n",
    "with open(os.getcwd() + os.sep + 'recommendation-data' + os.sep + MYTH + '-deberta-predictions.json', 'w') as f:\n",
    "    json.dump(model_prediction, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0149f7a1-766e-41f1-913d-41780dc539b4",
   "metadata": {},
   "source": [
    "## Parse through DEBERTA predictions & determine which to propagate to LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "781bb44d-c5d4-4ed8-9922-1cf5a44ea335",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_predictions_json(filepath):\n",
    "    with open(filepath, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    parsed_data = [\n",
    "        {\"video_id\": entry[0], \"label\": entry[1], \"confidence\": entry[2]}\n",
    "        for entry in data\n",
    "    ]\n",
    "\n",
    "    return parsed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f736957c-f006-4360-bb39-f47400ae3fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse through the deberta predictions, determining which to cascade up to the LLM\n",
    "def return_cascaded_videos(data, class_to_filter, threshold):\n",
    "    video_id_cascaded = []\n",
    "    for tuple in data:\n",
    "        video_id = tuple['video_id']\n",
    "        label = tuple['label']\n",
    "        confidence = float(tuple['confidence'])\n",
    "        \n",
    "        if label in class_to_filter or confidence < threshold:\n",
    "            video_id_cascaded.append(video_id)\n",
    "    return video_id_cascaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dab191-d8e6-4b2a-90fd-0b8f269acfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory containing data\n",
    "PREDICTION_DATA_DIR = os.getcwd() + os.sep + 'recommendation-data' + os.sep \n",
    "\n",
    "# Maximum Softmax Probability (MSP) Thresholds per myth\n",
    "MYTH_TO_THRESHOLD = {\n",
    "    'M1': 0.99,\n",
    "    'M2': 0.76, \n",
    "    'M3': 0.99,\n",
    "    'M4': 0.55,\n",
    "    'M5': 0.78,\n",
    "    'M6': 0.95,\n",
    "    'M7': 0.99,\n",
    "    'M8': 0.48\n",
    "}\n",
    "\n",
    "# Validation Error Tendencies (VET) classes to defer to GPT-4o\n",
    "class_to_filter = [0, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da84f5f-522c-466d-a34f-fce2ef1ab14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MYTH_TO_ID_LIST = defaultdict(list)\n",
    "total_videos = 0\n",
    "for MYTH, threshold in MYTH_TO_THRESHOLD.items():\n",
    "    # reading through the predictions\n",
    "    model_predictions = read_predictions_json(PREDICTION_DATA_DIR + MYTH + '-deberta-predictions.json')\n",
    "    video_id_for_cascading = return_cascaded_videos(model_predictions, class_to_filter, threshold)\n",
    "    MYTH_TO_ID_LIST[MYTH] = video_id_for_cascading\n",
    "    total_videos += len(video_id_for_cascading)\n",
    "    print(MYTH + \" list: \" + str(len(video_id_for_cascading)))\n",
    "\n",
    "print(total_videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9fa76b3b-9b0e-4904-ada7-22f4999365e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'myth_to_video_id_for_llm-redo.json'\n",
    "with open(filename, 'w', encoding='utf-8') as f:\n",
    "    json.dump(MYTH_TO_ID_LIST, f, indent=4, ensure_ascii=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
